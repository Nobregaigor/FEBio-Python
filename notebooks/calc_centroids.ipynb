{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('venv')",
   "display_name": "Python 3.8.3 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "4ce963eec525c72576d8dfcde812f8487bbeefd0db94f66638320c10fe71db33"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load geometry data\n",
    "\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "def find_files(path_to_folder, condition=None):\n",
    "\tif (condition):\n",
    "\t\tif (condition[0] == \"fileFormat\"):\n",
    "\t\t\t_l = len(condition[1])\n",
    "\t\t\treturn [(join(path_to_folder,f), f,f[:-_l - 1]) for f in listdir(path_to_folder) if isfile(join(path_to_folder, f)) and f[-_l:] == condition[1]]\n",
    "\t\telse:\n",
    "\t\t\traise(ValueError(\"Condition should be a tuple where the first argument is the condition name and the second is its value\"))\n",
    "\telse:\n",
    "\t\treturn [(join(path_to_folder,f), f, f.rsplit(\".\")[0]) for f in listdir(path_to_folder) if isfile(join(path_to_folder, f))]\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Load Pickles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import compiled data\n",
    "\n",
    "compiled_dir = \"./compiled_data\"\n",
    "elems_file = \"elems_compiled.pickle\"\n",
    "nodes_file = \"nodes_compiled.pickle\"\n",
    "\n",
    "e_p = join(compiled_dir, elems_file)\n",
    "n_p = join(compiled_dir, nodes_file)\n",
    "\n",
    "elems_df = pd.read_pickle(e_p)\n",
    "nodes_df = pd.read_pickle(n_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load geometry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get geometry files\n",
    "import pandas as pd\n",
    "GEOMETRY_FILES_PATH = \"./geometry_data\"\n",
    "\n",
    "files = find_files(GEOMETRY_FILES_PATH)\n",
    "\n",
    "# sort files\n",
    "geo_dict = {}\n",
    "for (fp, ff, fn) in files:\n",
    "    fs = fn.split(\"_\")\n",
    "    if fs[-1] == \"elems\":\n",
    "        key = fn.replace(\"_elems\",\"\")\n",
    "\n",
    "        df = pd.read_csv(fp, header=None, sep='\\n')\n",
    "        df = df[0].str.split(\",\",expand=True)\n",
    "        columns = [\"elem\"] + [*range(1,len(df.columns))]\n",
    "        df.columns = columns\n",
    "        df = df.apply(pd.to_numeric)\n",
    "\n",
    "        geo_dict[key] = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dict_keys(['myo_hex_coarse_8'])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "geo_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER_KEY = ['fileName']\n",
    "HEADER_TIM = ['time']\n",
    "HEADER_STR = ['sx','sy','sz','sxy','sxz','syz']\n",
    "HEADER_DIS = ['ux','uy','uz']\n",
    "HEADER_POS = ['x','y','z']\n",
    "HEADER_FAL = ['fail']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate centroids\n",
    "The calcuation of centroid of each element is needed to determine where the element is located. If it is close to the apex, it will have its value reduced\n",
    "- 1 Get the elemts and each node\n",
    "- 2 Get x,y,z for each node for each element\n",
    "- 3 Compute centroid for each element (x1,x2,x3... -> x)\n",
    "- 4 Add additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_name(fileName, nm=[0,4]):\n",
    "    splitted_name = fileName.replace(\"with_load_\",\"\").split(\"_epi\")[0].split(\"_\")\n",
    "    return \"_\".join([s for s in splitted_name[nm[0]:nm[1]]])\n",
    "\n",
    "def get_full_name(fileName):\n",
    "    return \"with_load_\" + fileName + \"_epi_60_endo_-60\"\n",
    "\n",
    "def hash_with_id(basename,id,time):\n",
    "    return hash(basename + \"-\" + str(int(id)) + \"-\" + str(float(time)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'myo_hex_8_coarse'"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "get_base_name(\"myo_hex_8_coarse_PAQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modified_dict():\n",
    "    def __init__(self, dataframe, _type):\n",
    "        self._type = _type\n",
    "        self.vec = dataframe.to_dict('records')\n",
    "        self.dict = self.transform(dataframe)\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.dict\n",
    "\n",
    "    def get(self, base_name, id, time, fileName=None):\n",
    "        if fileName != None:\n",
    "            base_name = get_base_name(fileName)\n",
    "        return self.dict[hash_with_id(base_name, id, time)]\n",
    "\n",
    "    def transform(self, dataframe, look_for=None):\n",
    "        new_dict = dict()\n",
    "        if look_for == None:\n",
    "            look_for = self._type\n",
    "        for con in self.vec:\n",
    "            con_num = con[look_for]\n",
    "            con_tim = con[\"time\"]\n",
    "            base_name = get_base_name(con[\"fileName\"])\n",
    "            hash_name = hash_with_id(base_name, con_num, con_tim)\n",
    "            new_dict.update({\n",
    "                hash_name: con\n",
    "            })\n",
    "        return new_dict\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_dict = Modified_dict(elems_df, \"elem\")\n",
    "node_dict = Modified_dict(nodes_df, \"node\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_dict.get(_, 74.0, 0.2, fileName=\"with_load_myo_hex_medium_8_epi_60_endo_-60\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.004, 0.2]\n"
    }
   ],
   "source": [
    "grouped_elems_df_time = elems_df.groupby([\"time\"])\n",
    "e_timesteps = list(grouped_elems_df_time.groups.keys())\n",
    "print(e_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       time     elem         sx       sy       sz        sxy       sxz  \\\n20000   0.2      1.0  -5.941120  52.3022 -13.7855 -16.729100  1.015420   \n20001   0.2      2.0  -0.126393  47.6513 -13.2595 -23.596200  1.420530   \n20002   0.2      3.0   6.939390  40.5597 -13.4835 -29.207900  1.805290   \n20003   0.2      4.0  15.490000  32.0672 -14.2087 -33.380800  2.190980   \n20004   0.2      5.0  26.938700  24.1022 -13.1274 -35.010500  2.548330   \n...     ...      ...        ...      ...      ...        ...       ...   \n79995   0.2  19996.0   4.458240  12.3052  27.8219   6.830940  2.449660   \n79996   0.2  19997.0   2.611210  13.9552  28.9259   5.530600  2.116080   \n79997   0.2  19998.0   1.488700  15.4157  28.9066   4.097190  1.292730   \n79998   0.2  19999.0   0.922051  16.6887  28.8449   2.301980  0.525949   \n79999   0.2  20000.0   0.066437  16.3722  27.5369   0.278788 -0.146879   \n\n           syz              fileName  \n20000 -3.05725  myo_hex_8_coarse_PAQ  \n20001 -2.95780  myo_hex_8_coarse_PAQ  \n20002 -2.73696  myo_hex_8_coarse_PAQ  \n20003 -2.48461  myo_hex_8_coarse_PAQ  \n20004 -2.17264  myo_hex_8_coarse_PAQ  \n...        ...                   ...  \n79995  4.41341  myo_hex_coarse_8_PAQ  \n79996  5.92202  myo_hex_coarse_8_PAQ  \n79997  5.50884  myo_hex_coarse_8_PAQ  \n79998  5.98947  myo_hex_coarse_8_PAQ  \n79999  4.86365  myo_hex_coarse_8_PAQ  \n\n[40000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>elem</th>\n      <th>sx</th>\n      <th>sy</th>\n      <th>sz</th>\n      <th>sxy</th>\n      <th>sxz</th>\n      <th>syz</th>\n      <th>fileName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20000</th>\n      <td>0.2</td>\n      <td>1.0</td>\n      <td>-5.941120</td>\n      <td>52.3022</td>\n      <td>-13.7855</td>\n      <td>-16.729100</td>\n      <td>1.015420</td>\n      <td>-3.05725</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>20001</th>\n      <td>0.2</td>\n      <td>2.0</td>\n      <td>-0.126393</td>\n      <td>47.6513</td>\n      <td>-13.2595</td>\n      <td>-23.596200</td>\n      <td>1.420530</td>\n      <td>-2.95780</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>20002</th>\n      <td>0.2</td>\n      <td>3.0</td>\n      <td>6.939390</td>\n      <td>40.5597</td>\n      <td>-13.4835</td>\n      <td>-29.207900</td>\n      <td>1.805290</td>\n      <td>-2.73696</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>20003</th>\n      <td>0.2</td>\n      <td>4.0</td>\n      <td>15.490000</td>\n      <td>32.0672</td>\n      <td>-14.2087</td>\n      <td>-33.380800</td>\n      <td>2.190980</td>\n      <td>-2.48461</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>20004</th>\n      <td>0.2</td>\n      <td>5.0</td>\n      <td>26.938700</td>\n      <td>24.1022</td>\n      <td>-13.1274</td>\n      <td>-35.010500</td>\n      <td>2.548330</td>\n      <td>-2.17264</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79995</th>\n      <td>0.2</td>\n      <td>19996.0</td>\n      <td>4.458240</td>\n      <td>12.3052</td>\n      <td>27.8219</td>\n      <td>6.830940</td>\n      <td>2.449660</td>\n      <td>4.41341</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79996</th>\n      <td>0.2</td>\n      <td>19997.0</td>\n      <td>2.611210</td>\n      <td>13.9552</td>\n      <td>28.9259</td>\n      <td>5.530600</td>\n      <td>2.116080</td>\n      <td>5.92202</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79997</th>\n      <td>0.2</td>\n      <td>19998.0</td>\n      <td>1.488700</td>\n      <td>15.4157</td>\n      <td>28.9066</td>\n      <td>4.097190</td>\n      <td>1.292730</td>\n      <td>5.50884</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79998</th>\n      <td>0.2</td>\n      <td>19999.0</td>\n      <td>0.922051</td>\n      <td>16.6887</td>\n      <td>28.8449</td>\n      <td>2.301980</td>\n      <td>0.525949</td>\n      <td>5.98947</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79999</th>\n      <td>0.2</td>\n      <td>20000.0</td>\n      <td>0.066437</td>\n      <td>16.3722</td>\n      <td>27.5369</td>\n      <td>0.278788</td>\n      <td>-0.146879</td>\n      <td>4.86365</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "grouped_elems_df_time.get_group(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Progress: 19900 | 20000 - 0 | 1'"
     },
     "metadata": {}
    }
   ],
   "source": [
    "from IPython.display import clear_output, display\n",
    "\n",
    "grouped_elems_df = elems_df.groupby([\"fileName\"])\n",
    "grouped_nodes_df = nodes_df.groupby([\"fileName\"])\n",
    "grouped_elems_df_time = elems_df.groupby([\"time\"])\n",
    "\n",
    "# grouped_elems_df_ft = elems_df.groupby([\"fileName\", \"time\"])\n",
    "\n",
    "# min_zs = grouped_elems_df_ft.min()[\"z\"]\n",
    "# max_zs = grouped_elems_df_ft.max()[\"z\"]\n",
    "\n",
    "e_keys = list(grouped_elems_df.groups.keys())\n",
    "n_keys = list(grouped_nodes_df.groups.keys())\n",
    "\n",
    "e_timesteps = list(grouped_elems_df_time.groups.keys())\n",
    "print()\n",
    "allowed_keys = e_keys + n_keys\n",
    "\n",
    "\n",
    "BASE = np.array([0.0, 0.0, 0.0])\n",
    "EPI_APEX = np.array([0.0, 0.0, -75.0])\n",
    "ENDO_APEX = np.array([0.0, 0.0, -65.0])\n",
    "\n",
    "def get_euclidean_dist(a,b):\n",
    "    return np.linalg.norm(a-b)\n",
    "def get_dist_to_line(P1, P2, P3):\n",
    "    return norm(np.cross(P2-P1, P1-P3))/norm(P2-P1)\n",
    "\n",
    "def get_nodes(geo_data):\n",
    "    _data = []\n",
    "    for i in range(1,8):\n",
    "        if i in geo_data and not np.isnan(geo_data[i]):\n",
    "            _data.append(geo_data[i])\n",
    "    return _data\n",
    "\n",
    "_f_max = len(geo_dict)\n",
    "for i, base_name in enumerate(geo_dict):\n",
    "    _e_max = len(geo_dict[base_name])\n",
    "\n",
    "    if base_name in allowed_keys:\n",
    "        continue\n",
    "\n",
    "    for j, geo_data in enumerate(geo_dict[base_name]):\n",
    "        elem_num = geo_data[\"elem\"]\n",
    "        elem_nodes = get_nodes(geo_data)\n",
    "        # print(elem_nodes)\n",
    "        \n",
    "        xsum = 0\n",
    "        ysum = 0 \n",
    "        zsum = 0\n",
    "        uxsum = 0\n",
    "        uysum = 0\n",
    "        uzsum = 0\n",
    "\n",
    "        for time_step in e_timesteps:\n",
    "            for node_num in elem_nodes:\n",
    "                # print(\"base_name\", base_name, \"node_num\", node_num)\n",
    "                try:\n",
    "                    node = node_dict.get(base_name, node_num, time_step)\n",
    "                    xsum += node[\"x\"]\n",
    "                    ysum += node[\"y\"]\n",
    "                    zsum += node[\"z\"]\n",
    "                    uxsum += node[\"ux\"]\n",
    "                    uysum += node[\"uy\"]\n",
    "                    uzsum += node[\"uz\"]\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            try:\n",
    "                elem = elem_dict.get(base_name, elem_num, time_step)\n",
    "\n",
    "                count = len(elem_nodes)\n",
    "                xm = xsum / count\n",
    "                ym = ysum / count\n",
    "                zm = zsum / count\n",
    "\n",
    "                cP = np.array([xm, ym, zm])\n",
    "\n",
    "                elem[\"x\"] = xsum / count\n",
    "                elem[\"y\"] = ysum / count\n",
    "                elem[\"z\"] = zsum / count\n",
    "                elem[\"ux\"] = uxsum / count\n",
    "                elem[\"uy\"] = uysum / count\n",
    "                elem[\"uz\"] = uzsum / count\n",
    "                elem[\"n_nodes\"] = count\n",
    "\n",
    "                # # calculate distances\n",
    "                # elem[\"d_min_z\"]  = abs(zm - min_zs[get_full_name(base_name)][time_step])\n",
    "                # elem[\"d_max_z\"]  = abs(zm - max_zs[get_full_name(base_name)][time_step])\n",
    "                # elem[\"d_center\"] = ym\n",
    "                \n",
    "                # calculate von mises (from https://forums.febio.org/archive/index.php/t-412.html)\n",
    "                vm = elem[\"sx\"] * elem[\"sx\"] + elem[\"sy\"] * elem[\"sy\"] + elem[\"sz\"] * elem[\"sz\"] \n",
    "                vm -= elem[\"sx\"] * elem[\"sy\"] + elem[\"sy\"] * elem[\"sz\"] + elem[\"sx\"] * elem[\"sz\"] \n",
    "                vm += 3 * (elem[\"sxy\"] * elem[\"sxy\"] + elem[\"syz\"] * elem[\"syz\"] + elem[\"sxz\"] * elem[\"sxz\"])\n",
    "\n",
    "                elem[\"vm\"] = np.sqrt(vm)\n",
    "\n",
    "            except Exception as e: \n",
    "                # print(e)\n",
    "                pass\n",
    "                \n",
    "        \n",
    "\n",
    "        if j % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            display(\"Progress: {curr_j} | {e_total} - {curr_i} | {f_total}\".format(curr_j=j,curr_i = i, e_total=_e_max, f_total=_f_max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem_list = list(elem_dict().values())\n",
    "new_elem_df = pd.DataFrame(elem_list, columns=list(elem_list[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"./compiled_data\"\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "new_elem_df.to_pickle(join(out_dir, \"elems_with_centroid\" + \".pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        time     elem        sx         sy         sz       sxy       sxz  \\\n0      0.004      1.0 -0.838460  -0.341764  -1.003850 -0.376963 -0.012362   \n1      0.004      2.0 -0.725720  -0.440269  -0.993483 -0.421445 -0.004908   \n2      0.004      3.0 -0.624983  -0.577933  -1.025380 -0.455080  0.001749   \n3      0.004      4.0 -0.484894  -0.707290  -1.042970 -0.463514  0.008015   \n4      0.004      5.0 -0.326624  -0.812571  -1.025780 -0.419058  0.014856   \n...      ...      ...       ...        ...        ...       ...       ...   \n79995  0.200  19996.0  4.458240  12.305200  27.821900  6.830940  2.449660   \n79996  0.200  19997.0  2.611210  13.955200  28.925900  5.530600  2.116080   \n79997  0.200  19998.0  1.488700  15.415700  28.906600  4.097190  1.292730   \n79998  0.200  19999.0  0.922051  16.688700  28.844900  2.301980  0.525949   \n79999  0.200  20000.0  0.066437  16.372200  27.536900  0.278788 -0.146879   \n\n            syz              fileName  \n0     -0.050719  myo_hex_8_coarse_PAQ  \n1     -0.055450  myo_hex_8_coarse_PAQ  \n2     -0.054960  myo_hex_8_coarse_PAQ  \n3     -0.052948  myo_hex_8_coarse_PAQ  \n4     -0.051715  myo_hex_8_coarse_PAQ  \n...         ...                   ...  \n79995  4.413410  myo_hex_coarse_8_PAQ  \n79996  5.922020  myo_hex_coarse_8_PAQ  \n79997  5.508840  myo_hex_coarse_8_PAQ  \n79998  5.989470  myo_hex_coarse_8_PAQ  \n79999  4.863650  myo_hex_coarse_8_PAQ  \n\n[80000 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>elem</th>\n      <th>sx</th>\n      <th>sy</th>\n      <th>sz</th>\n      <th>sxy</th>\n      <th>sxz</th>\n      <th>syz</th>\n      <th>fileName</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.004</td>\n      <td>1.0</td>\n      <td>-0.838460</td>\n      <td>-0.341764</td>\n      <td>-1.003850</td>\n      <td>-0.376963</td>\n      <td>-0.012362</td>\n      <td>-0.050719</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.004</td>\n      <td>2.0</td>\n      <td>-0.725720</td>\n      <td>-0.440269</td>\n      <td>-0.993483</td>\n      <td>-0.421445</td>\n      <td>-0.004908</td>\n      <td>-0.055450</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.004</td>\n      <td>3.0</td>\n      <td>-0.624983</td>\n      <td>-0.577933</td>\n      <td>-1.025380</td>\n      <td>-0.455080</td>\n      <td>0.001749</td>\n      <td>-0.054960</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.004</td>\n      <td>4.0</td>\n      <td>-0.484894</td>\n      <td>-0.707290</td>\n      <td>-1.042970</td>\n      <td>-0.463514</td>\n      <td>0.008015</td>\n      <td>-0.052948</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.004</td>\n      <td>5.0</td>\n      <td>-0.326624</td>\n      <td>-0.812571</td>\n      <td>-1.025780</td>\n      <td>-0.419058</td>\n      <td>0.014856</td>\n      <td>-0.051715</td>\n      <td>myo_hex_8_coarse_PAQ</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>79995</th>\n      <td>0.200</td>\n      <td>19996.0</td>\n      <td>4.458240</td>\n      <td>12.305200</td>\n      <td>27.821900</td>\n      <td>6.830940</td>\n      <td>2.449660</td>\n      <td>4.413410</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79996</th>\n      <td>0.200</td>\n      <td>19997.0</td>\n      <td>2.611210</td>\n      <td>13.955200</td>\n      <td>28.925900</td>\n      <td>5.530600</td>\n      <td>2.116080</td>\n      <td>5.922020</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79997</th>\n      <td>0.200</td>\n      <td>19998.0</td>\n      <td>1.488700</td>\n      <td>15.415700</td>\n      <td>28.906600</td>\n      <td>4.097190</td>\n      <td>1.292730</td>\n      <td>5.508840</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79998</th>\n      <td>0.200</td>\n      <td>19999.0</td>\n      <td>0.922051</td>\n      <td>16.688700</td>\n      <td>28.844900</td>\n      <td>2.301980</td>\n      <td>0.525949</td>\n      <td>5.989470</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n    <tr>\n      <th>79999</th>\n      <td>0.200</td>\n      <td>20000.0</td>\n      <td>0.066437</td>\n      <td>16.372200</td>\n      <td>27.536900</td>\n      <td>0.278788</td>\n      <td>-0.146879</td>\n      <td>4.863650</td>\n      <td>myo_hex_coarse_8_PAQ</td>\n    </tr>\n  </tbody>\n</table>\n<p>80000 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "new_elem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'vm'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Igor\\GitHub\\FEBio-Python\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vm'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-639a875d2a37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_elem_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"vm\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Igor\\GitHub\\FEBio-Python\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Igor\\GitHub\\FEBio-Python\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'vm'"
     ]
    }
   ],
   "source": [
    "new_elem_df[\"vm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform dataset\n",
    "\n",
    "- 1: Reduce high values around apex\n",
    "- 2: Reduce values of penta mesh\n",
    "- 3: Flatten spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute aditional info\n",
    "- Effective stress (von misses)\n",
    "- Centroidal displacement\n",
    "- Total displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute result\n",
    "- Mean values\n",
    "- Mean of max values (threshold) -> bins of 1% get max\n",
    "- Std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare each result\n",
    "- Compare each mesh density (coarse, medium, fine) for each result"
   ]
  }
 ]
}