{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression NN - v1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries:\n",
    "\n",
    "Requires the latest pip\n",
    "pip install --upgrade pip\n",
    "\n",
    "Current stable release for CPU and GPU\n",
    "pip install tensorflow\n",
    "\n",
    "Use seaborn for pairplot\n",
    "pip install -q seaborn\n",
    "\n",
    "Pandas library: pip install pandas\n",
    "Use some functions from tensorflow_docs\n",
    "pip install -q git+https://github.com/tensorflow/docs\n",
    "\n",
    "Numpy (if not already installed)\n",
    "pip install numpy\n",
    "\n",
    "Matplotlib (if not already installed)\n",
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# -----------\n",
    "\n",
    "# required libraries\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from enum import Enum, auto\n",
    "# seaborn\n",
    "import seaborn as sns\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# tensorflow_docs\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple enum class to determine study type\n",
    "class STUDY_TYPES(Enum):\n",
    "    ALL = auto()\n",
    "    NOT_FAILED = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs and features\n",
    "INPUT_PARAMS = ['a','b','time']\n",
    "HAS_FAILED_FEATURE = ['fail']\n",
    "STRESS_FEATURES = ['sx', 'sy', 'sz','sxy', 'sxz','syz']\n",
    "DISPLACEMENT_FEATURES = ['u{axis}_{node}'.format(axis=a, node=i) for i in range(1,9) for a in ['x', 'y', 'z']]\n",
    "\n",
    "INCLUDE_HAS_FAILED_FEATURE = False\n",
    "\n",
    "# Define training sample\n",
    "TRAIN_SAMPLE_FRAC = 0.8\n",
    "\n",
    "# Define range of data to analyse\n",
    "DATA_RANGE = (0,-1) # all\n",
    "\n",
    "# Define paths\n",
    "DATASET_PATH = 'C:\\\\Users\\\\igorp\\\\University of South Florida\\\\Mao, Wenbin - Myocardium (organized)\\\\Active\\\\Guccione_oneElem_study\\\\pickleData\\\\data.pickle'\n",
    "\n",
    "# Define split data type\n",
    "STUDY = STUDY_TYPES.NOT_FAILED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# -----------------\n",
    "\n",
    "# read pickle data and save as a pd dataset\n",
    "raw_dataset = pd.read_pickle(DATASET_PATH)\n",
    "# do not modify raw_data, instead, copy its instance\n",
    "dataset = raw_dataset.copy()\n",
    "# show some content\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if STUDY == STUDY_TYPES.NOT_FAILED:\n",
    "    print(\"len before:\", len(dataset))\n",
    "    dataset = dataset.drop(dataset[dataset['fail'] == 1.0].index) \n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    dataset.tail()\n",
    "    print(\"len after:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract inputs / features\n",
    "\n",
    "if INCLUDE_HAS_FAILED_FEATURE == True:\n",
    "    FEATURES = np.hstack((HAS_FAILED_FEATURE, DISPLACEMENT_FEATURES, STRESS_FEATURES))\n",
    "else:\n",
    "    FEATURES = np.hstack((DISPLACEMENT_FEATURES, STRESS_FEATURES))\n",
    "\n",
    "data_to_drop = [v for v in dataset.columns if v not in np.hstack((INPUT_PARAMS, FEATURES))]\n",
    "dataset = dataset.drop(data_to_drop, axis=1)\n",
    "\n",
    "# Crop dataset\n",
    "dataset = dataset[DATA_RANGE[0]:DATA_RANGE[1]]\n",
    "\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove values that are not numbers\n",
    "dataset = dataset.dropna()\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test datasets\n",
    "# Here, we are spliting 80% of the data for training and the rest for testing\n",
    "train_dataset = dataset.sample(frac=TRAIN_SAMPLE_FRAC,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpect data\n",
    "sns.pairplot(train_dataset[['a','b','time']], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data statistics\n",
    "train_stats = train_dataset.describe()\n",
    "train_stats = train_stats.drop(FEATURES, axis=1)\n",
    "train_stats = train_stats.transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split inputs and features\n",
    "train_labels = train_dataset.drop(INPUT_PARAMS, axis=1)     #outputs\n",
    "train_dataset = train_dataset.drop(FEATURES, axis=1)        #inputs\n",
    "\n",
    "test_labels = test_dataset.drop(INPUT_PARAMS, axis=1)\n",
    "test_dataset = test_dataset.drop(FEATURES, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "\n",
    "# normed_train_data = train_dataset\n",
    "# normed_test_data = test_dataset\n",
    "\n",
    "normed_train_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define build model\n",
    "\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "    layers.Dense(60, activation='relu', input_shape=[len(INPUT_PARAMS)]),\n",
    "    layers.Dense(80, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(140, activation='relu'),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(80, activation='relu'),\n",
    "    layers.Dense(len(FEATURES), activation='linear')\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.000001)\n",
    "\n",
    "\n",
    "    lossFunction = tf.keras.losses.MeanSquaredError()\n",
    "    metrics=['mae', 'mse']\n",
    "    # metrics=['mean_squared_error']\n",
    "\n",
    "\n",
    "    # model.compile(\n",
    "    #             loss='mse',\n",
    "    #             optimizer=optimizer,\n",
    "    #             metrics=['mae', 'mse'])\n",
    "\n",
    "    model.compile(\n",
    "            loss=lossFunction,\n",
    "            optimizer=optimizer,\n",
    "            metrics=metrics)\n",
    "\n",
    "    # model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and inspect model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out model\n",
    "normed_train_data.tail()\n",
    "example_batch = normed_train_data[-2:]\n",
    "\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model based on epochs\n",
    "EPOCHS = 1000\n",
    "\n",
    "# # The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(\n",
    "  train_dataset, \n",
    "  train_labels,\n",
    "  epochs=EPOCHS, \n",
    "  validation_split = 0.2, \n",
    "  verbose=0,\n",
    "  # batch_size=1,\n",
    "  # validation_data=(test_dataset, test_labels),\n",
    "  callbacks=[early_stop, tfdocs.modeling.EpochDots()]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
    "plotter.plot({'History': history}, metric = \"mae\")\n",
    "# plt.ylim([0, 10])\n",
    "plt.ylabel('MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model based on testing data\n",
    "\n",
    "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(normed_test_data)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.DataFrame(test_predictions, columns=FEATURES)\n",
    "test_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_vs_true_value(feature, title=None, lims=[0, 0.05]):\n",
    "    fig, a = plt.subplots()\n",
    "    a.scatter(test_labels[feature], test_predictions[feature])\n",
    "    a.set_xlabel('True Values [{fe}]'.format(fe=feature))\n",
    "    a.set_ylabel('Predictions [{fe}]'.format(fe=feature))\n",
    "    a.set_title(title)\n",
    "    lims = [np.min([test_labels[feature].min(), test_predictions[feature].min()]), \\\n",
    "            np.max([test_labels[feature].max(), test_predictions[feature].max()])]\n",
    "    a.set_xlim(lims)\n",
    "    a.set_ylim(lims)\n",
    "    a.set_aspect('equal')\n",
    "    # _ = a.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in FEATURES:\n",
    "    plot_prediction_vs_true_value(v, title=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_hist(feature, title=None):\n",
    "    error = test_predictions[feature] - test_labels[feature]\n",
    "    fig, a = plt.subplots()\n",
    "\n",
    "    a.hist(error, bins = 25)\n",
    "    a.set_xlabel(\"Prediction Error {fe}\".format(fe=feature))\n",
    "    a.set_title(title)\n",
    "    _ = a.set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in FEATURES:\n",
    "    plot_error_hist(v, title=v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "A = 1.2\n",
    "B = 2.5\n",
    "\n",
    "t_space = np.linspace(0,0.2,100)\n",
    "a_space = np.full(len(t_space), A)\n",
    "b_space = np.full(len(t_space), B)\n",
    "\n",
    "d = {'a': a_space, 'b': b_space, 'time': t_space}\n",
    "\n",
    "pred_inp = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(pred_inp)\n",
    "test_predictions = pd.DataFrame(test_predictions, columns=FEATURES)\n",
    "test_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(feature, title=None):\n",
    "    fig, a = plt.subplots()\n",
    "    a.scatter(pred_inp['time'], test_predictions[feature])\n",
    "\n",
    "    a.set_xlabel('time [s]')\n",
    "    a.set_ylabel('Predictions [{fe}]'.format(fe=feature))\n",
    "    \n",
    "    a.set_title(title)\n",
    "    # lims = [pred_inp['time'].min(), \\\n",
    "    #         np.max([test_labels[feature].max(), test_predictions[feature].max()])]\n",
    "    # a.set_xlim(lims)\n",
    "    # a.set_ylim(lims)\n",
    "    a.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve('ux_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve('sx')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}